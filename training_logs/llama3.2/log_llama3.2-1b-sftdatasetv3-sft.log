The following values were not passed to `accelerate launch` and had defaults used instead:
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
INFO:root:Using nproc_per_node=4.
[2025-04-29 14:30:33,977] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-29 14:30:33,981] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-29 14:30:33,983] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-29 14:30:33,986] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
2025-04-29:14:30:42 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-04-29:14:30:42 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-04-29:14:30:42 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-04-29:14:30:42 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-04-29:14:30:42 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-04-29:14:30:42 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-04-29:14:30:42 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-04-29:14:30:42 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-04-29:14:30:42 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-04-29:14:30:42 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-04-29:14:30:42 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/weights/llama3.2-1b-sftdatasetv3-sft-checkpoint-111000', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-04-29:14:30:42 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-04-29:14:30:42 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-04-29:14:30:42 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/weights/llama3.2-1b-sftdatasetv3-sft-checkpoint-111000', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-04-29:14:30:42 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-04-29:14:30:42 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-04-29:14:30:42 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/weights/llama3.2-1b-sftdatasetv3-sft-checkpoint-111000', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-04-29:14:30:42 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-04-29:14:30:42 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-04-29:14:30:42 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/weights/llama3.2-1b-sftdatasetv3-sft-checkpoint-111000', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-04-29:14:30:43 INFO     [models.huggingface:382] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
2025-04-29:14:30:43 INFO     [models.huggingface:382] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:3'}
2025-04-29:14:30:43 INFO     [models.huggingface:382] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:1'}
2025-04-29:14:30:43 INFO     [models.huggingface:382] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:2'}
