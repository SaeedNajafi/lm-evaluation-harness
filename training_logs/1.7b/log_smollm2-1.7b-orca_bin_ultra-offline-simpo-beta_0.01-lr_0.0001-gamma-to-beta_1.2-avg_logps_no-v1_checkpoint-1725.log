The following values were not passed to `accelerate launch` and had defaults used instead:
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
INFO:root:Using nproc_per_node=4.
[2025-05-10 18:04:43,499] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-10 18:04:43,507] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-10 18:04:43,509] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-10 18:04:43,535] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
2025-05-10:18:04:50 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-05-10:18:04:50 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-05-10:18:04:50 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-05-10:18:04:50 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-05-10:18:04:50 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-05-10:18:04:50 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-05-10:18:04:50 INFO     [__main__:428] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-05-10:18:04:50 INFO     [__main__:440] Selected Tasks: ['arc_challenge', 'arc_easy', 'commonsense_qa', 'hellaswag', 'mathqa', 'mmlu', 'openbookqa', 'piqa', 'race', 'winogrande']
2025-05-10:18:04:50 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-05-10:18:04:50 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-05-10:18:04:50 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-05-10:18:04:50 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-05-10:18:04:50 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-05-10:18:04:50 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-05-10:18:04:50 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-05-10:18:04:50 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-05-10:18:04:50 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725', 'dtype': 'bfloat16', 'trust_remote_code': True}
2025-05-10:18:04:50 INFO     [evaluator:185] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-05-10:18:04:50 WARNING  [evaluator:197] generation_kwargs: {'max_new_tokens': 1024, 'do_sample': False} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-05-10:18:04:50 INFO     [evaluator:223] Initializing hf model, with arguments: {'pretrained': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725', 'dtype': 'bfloat16', 'trust_remote_code': True}
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 424, in cached_files
[rank0]:     hf_hub_download(
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank0]:     validate_repo_id(arg_value)
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank0]:     raise HFValidationError(
[rank0]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
[rank0]:     resolved_config_file = cached_file(
[rank0]:                            ^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 266, in cached_file
[rank0]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank0]:     resolved_files = [
[rank0]:                      ^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 471, in <listcomp>
[rank0]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 134, in _get_cache_file_to_return
[rank0]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank0]:     validate_repo_id(arg_value)
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank0]:     raise HFValidationError(
[rank0]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank0]: During handling of the above exception, another exception occurred:

[rank0]: Traceback (most recent call last):
[rank0]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank0]:   File "<frozen runpy>", line 88, in _run_code
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank0]:     cli_evaluate()
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank0]:     results = evaluator.simple_evaluate(
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank0]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank0]:     return cls(**args, **args2)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank0]:     self._get_config(
[rank0]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank0]:     self._config = transformers.AutoConfig.from_pretrained(
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1114, in from_pretrained
[rank0]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
[rank0]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank0]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 672, in _get_config_dict
[rank0]:     raise OSError(
[rank0]: OSError: Can't load the configuration of '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725' is the correct path to a directory containing a config.json file
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 424, in cached_files
[rank2]:     hf_hub_download(
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank2]:     validate_repo_id(arg_value)
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank2]:     raise HFValidationError(
[rank2]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank2]: During handling of the above exception, another exception occurred:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
[rank2]:     resolved_config_file = cached_file(
[rank2]:                            ^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 266, in cached_file
[rank2]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank2]:     resolved_files = [
[rank2]:                      ^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 471, in <listcomp>
[rank2]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank2]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 134, in _get_cache_file_to_return
[rank2]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank2]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank2]:     validate_repo_id(arg_value)
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank2]:     raise HFValidationError(
[rank2]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank2]: During handling of the above exception, another exception occurred:

[rank2]: Traceback (most recent call last):
[rank2]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank2]:   File "<frozen runpy>", line 88, in _run_code
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank2]:     cli_evaluate()
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank2]:     results = evaluator.simple_evaluate(
[rank2]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank2]:     return fn(*args, **kwargs)
[rank2]:            ^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank2]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank2]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank2]:     return cls(**args, **args2)
[rank2]:            ^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank2]:     self._get_config(
[rank2]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank2]:     self._config = transformers.AutoConfig.from_pretrained(
[rank2]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1114, in from_pretrained
[rank2]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank2]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
[rank2]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank2]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 672, in _get_config_dict
[rank2]:     raise OSError(
[rank2]: OSError: Can't load the configuration of '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725' is the correct path to a directory containing a config.json file
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 424, in cached_files
[rank3]:     hf_hub_download(
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank3]:     validate_repo_id(arg_value)
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank3]:     raise HFValidationError(
[rank3]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank3]: During handling of the above exception, another exception occurred:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
[rank3]:     resolved_config_file = cached_file(
[rank3]:                            ^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 266, in cached_file
[rank3]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank3]:     resolved_files = [
[rank3]:                      ^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 471, in <listcomp>
[rank3]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank3]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 134, in _get_cache_file_to_return
[rank3]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank3]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank3]:     validate_repo_id(arg_value)
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank3]:     raise HFValidationError(
[rank3]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank3]: During handling of the above exception, another exception occurred:

[rank3]: Traceback (most recent call last):
[rank3]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank3]:   File "<frozen runpy>", line 88, in _run_code
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank3]:     cli_evaluate()
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank3]:     results = evaluator.simple_evaluate(
[rank3]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank3]:     return fn(*args, **kwargs)
[rank3]:            ^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank3]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank3]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank3]:     return cls(**args, **args2)
[rank3]:            ^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank3]:     self._get_config(
[rank3]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank3]:     self._config = transformers.AutoConfig.from_pretrained(
[rank3]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1114, in from_pretrained
[rank3]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank3]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
[rank3]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank3]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 672, in _get_config_dict
[rank3]:     raise OSError(
[rank3]: OSError: Can't load the configuration of '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725' is the correct path to a directory containing a config.json file
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 424, in cached_files
[rank1]:     hf_hub_download(
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank1]:     validate_repo_id(arg_value)
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank1]:     raise HFValidationError(
[rank1]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 649, in _get_config_dict
[rank1]:     resolved_config_file = cached_file(
[rank1]:                            ^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 266, in cached_file
[rank1]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 470, in cached_files
[rank1]:     resolved_files = [
[rank1]:                      ^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 471, in <listcomp>
[rank1]:     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames
[rank1]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/utils/hub.py", line 134, in _get_cache_file_to_return
[rank1]:     resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)
[rank1]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
[rank1]:     validate_repo_id(arg_value)
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
[rank1]:     raise HFValidationError(
[rank1]: huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. Use `repo_type` argument if needed.

[rank1]: During handling of the above exception, another exception occurred:

[rank1]: Traceback (most recent call last):
[rank1]:   File "<frozen runpy>", line 198, in _run_module_as_main
[rank1]:   File "<frozen runpy>", line 88, in _run_code
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 530, in <module>
[rank1]:     cli_evaluate()
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 449, in cli_evaluate
[rank1]:     results = evaluator.simple_evaluate(
[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/utils.py", line 439, in _wrapper
[rank1]:     return fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 226, in simple_evaluate
[rank1]:     lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/api/model.py", line 151, in create_from_arg_string
[rank1]:     return cls(**args, **args2)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 168, in __init__
[rank1]:     self._get_config(
[rank1]:   File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/huggingface.py", line 527, in _get_config
[rank1]:     self._config = transformers.AutoConfig.from_pretrained(
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 1114, in from_pretrained
[rank1]:     config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank1]:                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 590, in get_config_dict
[rank1]:     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
[rank1]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/transformers/configuration_utils.py", line 672, in _get_config_dict
[rank1]:     raise OSError(
[rank1]: OSError: Can't load the configuration of '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/saeednjf/projects/def-afyshe-ab/saeednjf/checkpoints/smollm2/simpo_final/smollm2-1.7b-orca_bin_ultra-offline-simpo-beta_0.01-lr_0.0001-gamma-to-beta_1.2-avg_logps_no-v1/checkpoint-1725' is the correct path to a directory containing a config.json file
W0510 18:04:52.177000 124701271983936 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 859895 closing signal SIGTERM
W0510 18:04:52.178000 124701271983936 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 859896 closing signal SIGTERM
W0510 18:04:52.178000 124701271983936 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 859897 closing signal SIGTERM
E0510 18:04:52.292000 124701271983936 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 859894) of binary: /home/saeednjf/miniconda3/envs/llm-env/bin/python
Traceback (most recent call last):
  File "/home/saeednjf/miniconda3/envs/llm-env/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1204, in launch_command
    multi_gpu_launcher(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/launch.py", line 825, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
lm_eval FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-10_18:04:52
  host      : rack01-09
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 859894)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
