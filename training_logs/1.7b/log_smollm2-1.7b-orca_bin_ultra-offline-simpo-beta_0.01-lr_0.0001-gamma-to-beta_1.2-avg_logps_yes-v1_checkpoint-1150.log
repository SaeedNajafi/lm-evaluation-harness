/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:843: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  r = torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
INFO:root:Using nproc_per_node=4.
/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
[2025-05-10 17:52:43,565] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2025-05-10 17:52:43,566] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[2025-05-10 17:52:43,579] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2025-05-10 17:52:43,580] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[2025-05-10 17:52:43,583] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2025-05-10 17:52:43,584] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[2025-05-10 17:52:43,592] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2025-05-10 17:52:43,593] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.

Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Warning: The cache directory for DeepSpeed Triton autotune, /home/saeednjf/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 10, in <module>
    from lm_eval import evaluator, utils
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__init__.py", line 4, in <module>
    from .evaluator import evaluate, simple_evaluate
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 15, in <module>
    import lm_eval.models
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/__init__.py", line 1, in <module>
    from . import (
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/vllm_causallms.py", line 28, in <module>
    from vllm import LLM, SamplingParams
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from vllm.config import (CacheConfig, ConfigFormat, DecodingConfig,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/config.py", line 12, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/__init__.py", line 1, in <module>
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/parameter.py", line 7, in <module>
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/__init__.py", line 1, in <module>
    from .communication_op import *
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/communication_op.py", line 6, in <module>
    from .parallel_state import get_tp_group
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/parallel_state.py", line 38, in <module>
    from vllm.platforms import current_platform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/__init__.py", line 67, in <module>
    from .cuda import CudaPlatform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 86, in <module>
    warn_if_different_devices()
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in warn_if_different_devices
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in <listcomp>
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 10, in <module>
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    from lm_eval import evaluator, utils
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__init__.py", line 4, in <module>
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 58, in get_physical_device_name
    from .evaluator import evaluate, simple_evaluate
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 15, in <module>
    handle = pynvml.nvmlDeviceGetHandleByIndex(device_id)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^import lm_eval.models^

  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 2604, in nvmlDeviceGetHandleByIndex
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/__init__.py", line 1, in <module>
    from . import (
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/vllm_causallms.py", line 28, in <module>
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 10, in <module>
    from vllm import LLM, SamplingParams
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
    from lm_eval import evaluator, utils
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__init__.py", line 4, in <module>
    _nvmlCheckReturn(ret)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 1042, in _nvmlCheckReturn
    from vllm.config import (CacheConfig, ConfigFormat, DecodingConfig,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/config.py", line 12, in <module>
    from .evaluator import evaluate, simple_evaluate
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 15, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/__init__.py", line 1, in <module>
    import lm_eval.models
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/__init__.py", line 1, in <module>
    raise NVMLError(ret)
pynvml.NVMLError_Unknown: Unknown Error
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/parameter.py", line 7, in <module>
    from . import (
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/vllm_causallms.py", line 28, in <module>
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/__init__.py", line 1, in <module>
    from vllm import LLM, SamplingParams
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/__init__.py", line 3, in <module>
    from .communication_op import *
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/communication_op.py", line 6, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    from .parallel_state import get_tp_group
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/parallel_state.py", line 38, in <module>
    from vllm.config import (CacheConfig, ConfigFormat, DecodingConfig,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/config.py", line 12, in <module>
    from vllm.platforms import current_platform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/__init__.py", line 67, in <module>
    from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/__init__.py", line 1, in <module>
    from .cuda import CudaPlatform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 86, in <module>
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/parameter.py", line 7, in <module>
    warn_if_different_devices()
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/__init__.py", line 1, in <module>
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in warn_if_different_devices
    from .communication_op import *
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/communication_op.py", line 6, in <module>
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
    from .parallel_state import get_tp_group
           File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/parallel_state.py", line 38, in <module>
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in <listcomp>
    from vllm.platforms import current_platform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/__init__.py", line 67, in <module>
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
 Traceback (most recent call last):
       File "<frozen runpy>", line 198, in _run_module_as_main
     File "<frozen runpy>", line 88, in _run_code
      File "/home/saeednjf/lm-evaluation-harness/lm_eval/__main__.py", line 10, in <module>
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    from .cuda import CudaPlatform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 86, in <module>
    return fn(*args, **kwargs)
           ^^^    ^warn_if_different_devices()^
^^^^^^^^^^^    ^from lm_eval import evaluator, utils^
^  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper

  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 58, in get_physical_device_name
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/__init__.py", line 4, in <module>
    return fn(*args, **kwargs)
    handle = pynvml.nvmlDeviceGetHandleByIndex(device_id)
               ^     ^from .evaluator import evaluate, simple_evaluate ^
 ^ ^ ^ ^ ^ ^ ^^^^^  File "/home/saeednjf/lm-evaluation-harness/lm_eval/evaluator.py", line 15, in <module>
^^^^^^^^^^^^^^^
^^^  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in warn_if_different_devices
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 2604, in nvmlDeviceGetHandleByIndex
    import lm_eval.models
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/__init__.py", line 1, in <module>
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^from . import (^
^^^
  File "/home/saeednjf/lm-evaluation-harness/lm_eval/models/vllm_causallms.py", line 28, in <module>
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in <listcomp>
    from vllm import LLM, SamplingParams
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/__init__.py", line 3, in <module>
            _nvmlCheckReturn(ret) 
           File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 1042, in _nvmlCheckReturn
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/engine/arg_utils.py", line 11, in <module>
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^    ^raise NVMLError(ret)^
^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 58, in get_physical_device_name
    pynvmlfrom vllm.config import (CacheConfig, ConfigFormat, DecodingConfig,.
NVMLError_Unknown  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/config.py", line 12, in <module>
: Unknown Error
    handle = pynvml.nvmlDeviceGetHandleByIndex(device_id)
     from vllm.model_executor.layers.quantization import QUANTIZATION_METHODS 
            File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/__init__.py", line 1, in <module>
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 2604, in nvmlDeviceGetHandleByIndex
    from vllm.model_executor.parameter import (BasevLLMParameter,
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/model_executor/parameter.py", line 7, in <module>
    from vllm.distributed import get_tensor_model_parallel_rank
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/__init__.py", line 1, in <module>
    from .communication_op import *
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/communication_op.py", line 6, in <module>
    from .parallel_state import get_tp_group
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/distributed/parallel_state.py", line 38, in <module>
    _nvmlCheckReturn(ret)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 1042, in _nvmlCheckReturn
    from vllm.platforms import current_platform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/__init__.py", line 67, in <module>
    from .cuda import CudaPlatform
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 86, in <module>
    raise NVMLError(ret)
pynvml.NVMLError_Unknown: Unknown Error
    warn_if_different_devices()
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in warn_if_different_devices
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 73, in <listcomp>
    device_names = [get_physical_device_name(i) for i in range(device_ids)]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 41, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/vllm/platforms/cuda.py", line 58, in get_physical_device_name
    handle = pynvml.nvmlDeviceGetHandleByIndex(device_id)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 2604, in nvmlDeviceGetHandleByIndex
    _nvmlCheckReturn(ret)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/pynvml.py", line 1042, in _nvmlCheckReturn
    raise NVMLError(ret)
pynvml.NVMLError_Unknown: Unknown Error
W0510 17:52:45.674000 128210842736448 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1348488 closing signal SIGTERM
W0510 17:52:45.674000 128210842736448 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1348489 closing signal SIGTERM
W0510 17:52:45.674000 128210842736448 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1348490 closing signal SIGTERM
E0510 17:52:45.738000 128210842736448 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1348487) of binary: /home/saeednjf/miniconda3/envs/llm-env/bin/python
Traceback (most recent call last):
  File "/home/saeednjf/miniconda3/envs/llm-env/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1204, in launch_command
    multi_gpu_launcher(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/accelerate/commands/launch.py", line 825, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/saeednjf/miniconda3/envs/llm-env/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
lm_eval FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-10_17:52:45
  host      : rack02-06
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1348487)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
